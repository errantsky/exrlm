<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>RLM Architecture Discussion &mdash; The Recursion Engine</title>
<style>
  :root {
    --bg: #0d1017;
    --surface: #131720;
    --surface2: #1a1f2e;
    --surface3: #222738;
    --border: #2d3348;
    --text: #c5c9d6;
    --text-dim: #6e7590;
    --heading: #e8eaf2;
    --accent: #e8985a;
    --accent-light: #f0b078;
    --accent-dim: rgba(232,152,90,0.12);
    --accent-border: rgba(232,152,90,0.25);
    --green: #7ec699;
    --green-dim: rgba(126,198,153,0.12);
    --blue: #7aa2f7;
    --blue-dim: rgba(122,162,247,0.12);
    --red: #f07178;
    --red-dim: rgba(240,113,120,0.12);
    --purple: #c4a7e7;
    --purple-dim: rgba(196,167,231,0.12);
    --teal: #7dcfff;
    --teal-dim: rgba(125,207,255,0.12);
    --yellow: #e0c080;
    --yellow-dim: rgba(224,192,128,0.12);
    --font: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
    --mono: 'JetBrains Mono', 'Fira Code', 'Cascadia Code', monospace;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    font-family: var(--font);
    background: var(--bg);
    color: var(--text);
    line-height: 1.7;
    font-size: 15px;
  }

  .container { max-width: 1100px; margin: 0 auto; padding: 0 28px; }

  /* ---- Header ---- */
  header {
    background: linear-gradient(135deg, #1a1020 0%, #0d1017 50%, #0d1520 100%);
    border-bottom: 1px solid var(--border);
    padding: 56px 0 48px;
    text-align: center;
  }
  header h1 {
    font-size: 2.2rem;
    font-weight: 700;
    background: linear-gradient(135deg, var(--accent) 0%, var(--accent-light) 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    margin-bottom: 12px;
  }
  header .subtitle {
    font-size: 1.05rem;
    color: var(--text-dim);
    max-width: 650px;
    margin: 0 auto 20px;
    line-height: 1.6;
  }
  header .meta {
    display: flex;
    justify-content: center;
    gap: 24px;
    flex-wrap: wrap;
  }
  header .meta-item {
    color: var(--text-dim);
    font-size: 0.82rem;
  }
  header .meta-item strong { color: var(--text); }

  /* ---- Navigation ---- */
  nav {
    position: sticky;
    top: 0;
    z-index: 100;
    background: rgba(13,16,23,0.85);
    backdrop-filter: blur(12px);
    border-bottom: 1px solid var(--border);
    padding: 0;
  }
  nav .container {
    display: flex;
    gap: 4px;
    overflow-x: auto;
    padding: 10px 28px;
  }
  nav a {
    color: var(--text-dim);
    text-decoration: none;
    font-size: 0.78rem;
    font-weight: 500;
    padding: 5px 12px;
    border-radius: 6px;
    white-space: nowrap;
    transition: all 0.15s;
  }
  nav a:hover { color: var(--accent); background: var(--accent-dim); }

  /* ---- Sections ---- */
  section { padding: 56px 0; border-bottom: 1px solid var(--border); }
  section:last-of-type { border-bottom: none; }
  h2 {
    font-size: 1.55rem;
    font-weight: 700;
    color: var(--heading);
    margin-bottom: 28px;
    display: flex;
    align-items: center;
    gap: 12px;
  }
  h2 .section-num {
    font-size: 0.85rem;
    color: var(--accent);
    font-weight: 600;
    min-width: 28px;
  }
  h3 {
    font-size: 1.15rem;
    font-weight: 600;
    color: var(--heading);
    margin: 32px 0 14px;
  }
  h4 {
    font-size: 0.95rem;
    font-weight: 600;
    color: var(--accent-light);
    margin: 22px 0 10px;
  }
  p { margin-bottom: 16px; }

  /* ---- Diagrams ---- */
  .diagram {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 10px;
    padding: 24px 28px;
    margin: 20px 0 24px;
    overflow-x: auto;
    font-family: var(--mono);
    font-size: 0.78rem;
    line-height: 1.65;
    white-space: pre;
  }
  .diagram .proc { color: var(--accent); font-weight: 600; }
  .diagram .msg { color: var(--teal); }
  .diagram .state { color: var(--purple); }
  .diagram .action { color: var(--green); }
  .diagram .warn { color: var(--red); }
  .diagram .dim { color: var(--text-dim); }
  .diagram .hl { color: var(--yellow); }
  .diagram .label { color: var(--text); font-weight: 600; }

  /* ---- Code ---- */
  pre.code {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 8px;
    padding: 18px 22px;
    margin: 14px 0 20px;
    overflow-x: auto;
    font-family: var(--mono);
    font-size: 0.78rem;
    line-height: 1.7;
    color: #c8d0e0;
  }
  code {
    font-family: var(--mono);
    font-size: 0.85em;
    background: var(--surface2);
    padding: 2px 6px;
    border-radius: 4px;
    color: var(--accent-light);
  }
  pre.code code { background: none; padding: 0; border-radius: 0; }
  .kw { color: #c792ea; }
  .fn { color: #82aaff; }
  .str { color: #c3e88d; }
  .at { color: #f78c6c; }
  .cm { color: #546e7a; font-style: italic; }
  .num { color: #f78c6c; }
  .var { color: #eeffff; }
  .mod { color: #ffcb6b; }

  /* ---- Cards ---- */
  .card-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
    gap: 16px;
    margin: 18px 0 24px;
  }
  .card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 10px;
    padding: 22px 24px;
  }
  .card h4 { margin-top: 0; }
  .card p:last-child { margin-bottom: 0; }

  .card.pro { border-left: 3px solid var(--green); }
  .card.con { border-left: 3px solid var(--red); }
  .card.alt { border-left: 3px solid var(--blue); }
  .card.note { border-left: 3px solid var(--yellow); }

  /* ---- Tags ---- */
  .tag {
    display: inline-block;
    font-size: 0.72rem;
    font-weight: 600;
    padding: 2px 8px;
    border-radius: 4px;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-right: 6px;
  }
  .tag-otp { background: var(--purple-dim); color: var(--purple); }
  .tag-legibility { background: var(--blue-dim); color: var(--blue); }
  .tag-error { background: var(--red-dim); color: var(--red); }
  .tag-maintenance { background: var(--yellow-dim); color: var(--yellow); }
  .tag-perf { background: var(--green-dim); color: var(--green); }
  .tag-complexity { background: var(--accent-dim); color: var(--accent); }

  /* ---- Tables ---- */
  table {
    width: 100%;
    border-collapse: collapse;
    margin: 16px 0 24px;
    font-size: 0.88rem;
  }
  th, td {
    padding: 10px 14px;
    text-align: left;
    border-bottom: 1px solid var(--border);
  }
  th {
    background: var(--surface);
    color: var(--heading);
    font-weight: 600;
    font-size: 0.82rem;
    text-transform: uppercase;
    letter-spacing: 0.5px;
  }
  tr:hover td { background: var(--surface); }

  /* ---- Callouts ---- */
  .callout {
    background: var(--surface);
    border-left: 3px solid var(--accent);
    border-radius: 0 8px 8px 0;
    padding: 18px 22px;
    margin: 20px 0;
  }
  .callout.deadlock { border-left-color: var(--red); background: var(--red-dim); }
  .callout.insight { border-left-color: var(--teal); }
  .callout.key { border-left-color: var(--yellow); }
  .callout-title {
    font-weight: 700;
    font-size: 0.85rem;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-bottom: 8px;
  }
  .callout.deadlock .callout-title { color: var(--red); }
  .callout.insight .callout-title { color: var(--teal); }
  .callout.key .callout-title { color: var(--yellow); }

  /* ---- Comparison ---- */
  .comparison {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 16px;
    margin: 20px 0;
  }
  .comparison > div {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 10px;
    padding: 20px 22px;
  }

  /* ---- Details/Collapsible ---- */
  details {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 8px;
    margin: 12px 0;
    overflow: hidden;
  }
  details summary {
    padding: 14px 20px;
    cursor: pointer;
    font-weight: 600;
    color: var(--heading);
    font-size: 0.92rem;
    list-style: none;
  }
  details summary::before {
    content: '\25B6';
    display: inline-block;
    margin-right: 10px;
    font-size: 0.7rem;
    transition: transform 0.2s;
    color: var(--accent);
  }
  details[open] summary::before { transform: rotate(90deg); }
  details .content { padding: 0 20px 18px; }

  /* ---- Verdict ---- */
  .verdict-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 14px;
    margin: 20px 0;
  }
  .verdict-item {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 8px;
    padding: 18px;
    text-align: center;
  }
  .verdict-item .score {
    font-size: 1.8rem;
    font-weight: 800;
    margin-bottom: 4px;
  }
  .verdict-item .score.high { color: var(--green); }
  .verdict-item .score.mid { color: var(--yellow); }
  .verdict-item .score.low { color: var(--red); }
  .verdict-item .label {
    font-size: 0.78rem;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 0.5px;
  }

  /* ---- Flow Arrows ---- */
  .flow-step {
    display: flex;
    align-items: stretch;
    margin: 16px 0;
    gap: 0;
  }
  .flow-num {
    background: var(--accent-dim);
    border: 1px solid var(--accent-border);
    border-radius: 8px 0 0 8px;
    padding: 16px 18px;
    font-size: 1.4rem;
    font-weight: 800;
    color: var(--accent);
    display: flex;
    align-items: center;
    min-width: 56px;
    justify-content: center;
  }
  .flow-body {
    background: var(--surface);
    border: 1px solid var(--border);
    border-left: none;
    border-radius: 0 8px 8px 0;
    padding: 16px 20px;
    flex: 1;
  }
  .flow-body strong { color: var(--heading); }

  /* ---- Responsive ---- */
  @media (max-width: 768px) {
    header h1 { font-size: 1.6rem; }
    .comparison { grid-template-columns: 1fr; }
    .card-grid { grid-template-columns: 1fr; }
    .verdict-grid { grid-template-columns: repeat(2, 1fr); }
    section { padding: 36px 0; }
  }

  html { scroll-behavior: smooth; }
  ::selection { background: rgba(232,152,90,0.3); }
</style>
</head>
<body>

<header>
  <div class="container">
    <h1>The Recursion Engine</h1>
    <div class="subtitle">
      An architectural deep-dive into how RLM Workers orchestrate recursive LLM
      execution, the trade-offs of the current design, and alternative architectures.
    </div>
    <div class="meta">
      <span class="meta-item">Project: <strong>RLM Umbrella</strong></span>
      <span class="meta-item">Scope: <strong>Worker, Eval, Sandbox, OTP</strong></span>
      <span class="meta-item">Generated: <strong>Feb 2026</strong></span>
    </div>
  </div>
</header>

<nav>
  <div class="container">
    <a href="#overview">Overview</a>
    <a href="#iterate">Iterate Loop</a>
    <a href="#deadlock">The Deadlock</a>
    <a href="#subcalls">Subcalls</a>
    <a href="#direct-query">Direct Query</a>
    <a href="#message-flow">Message Flow</a>
    <a href="#otp">OTP Analysis</a>
    <a href="#pros">Pros</a>
    <a href="#cons">Cons</a>
    <a href="#alternatives">Alternatives</a>
    <a href="#verdict">Verdict</a>
  </div>
</nav>

<!-- ================================================================== -->
<!-- SECTION 1: OVERVIEW -->
<!-- ================================================================== -->
<section id="overview">
  <div class="container">
    <h2><span class="section-num">01</span> What the Recursion Engine Does</h2>

    <p>
      RLM is a <strong>Recursive Language Model</strong> engine. At its core, it runs
      an iterative loop: ask an LLM to write Elixir code, execute that code in a
      sandboxed REPL, feed the results back to the LLM, and repeat until the LLM
      sets <code>final_answer</code>.
    </p>
    <p>
      The twist is <em>recursion</em>. The code the LLM writes can itself invoke
      <code>lm_query()</code>, which spawns an entirely new Worker with its own
      iterate loop. That child can spawn grandchildren. The result is a tree of
      LLM-driven computations, coordinated through OTP processes.
    </p>

    <h3>The Cast of Processes</h3>

    <div class="diagram"><span class="label">Process Roles in a Single RLM Execution</span>

<span class="proc">Caller</span>          The process that called <span class="fn">RLM.run/3</span>. Blocks in a <span class="kw">receive</span> loop.

<span class="proc">Worker</span>          A <span class="mod">GenServer</span> that owns the iterate loop state: message history,
                 bindings, iteration count, pending subcalls.

<span class="proc">Eval Process</span>    A short-lived <span class="fn">spawn</span>'d process that runs <span class="fn">Code.eval_string</span>.
                 Communicates with the Worker via <span class="msg">GenServer.call</span> and <span class="msg">send</span>.

<span class="proc">Child Worker</span>    Another Worker GenServer, spawned under the same DynamicSupervisor,
                 at <span class="state">depth + 1</span>. Has its own iterate loop.</div>

    <h3>How They Connect</h3>

    <div class="diagram"><span class="label">Supervision &amp; Ownership</span>

<span class="proc">RLM.WorkerSup</span> <span class="dim">(DynamicSupervisor)</span>
  <span class="dim">&#9500;&#9472;&#9472;</span> <span class="proc">Worker A</span> <span class="dim">(depth=0, :temporary)</span>
  <span class="dim">&#9500;&#9472;&#9472;</span> <span class="proc">Worker B</span> <span class="dim">(depth=1, :temporary, spawned by A)</span>
  <span class="dim">&#9492;&#9472;&#9472;</span> <span class="proc">Worker C</span> <span class="dim">(depth=2, :temporary, spawned by B)</span>

<span class="dim">All Workers are siblings under the same DynamicSupervisor.</span>
<span class="dim">Parent-child relationships exist only in application logic</span>
<span class="dim">(caller PID, pending_subcalls), not in the OTP supervision tree.</span></div>

    <div class="callout key">
      <div class="callout-title">Key Insight</div>
      The OTP supervision tree is <em>flat</em> &mdash; all Workers are peers under one
      DynamicSupervisor. The recursive parent-child relationship is maintained through
      message passing: a parent Worker stores the child's <code>span_id</code> in its
      <code>pending_subcalls</code> map and receives results via <code>{:rlm_result, ...}</code>.
    </div>
  </div>
</section>

<!-- ================================================================== -->
<!-- SECTION 2: THE ITERATE LOOP -->
<!-- ================================================================== -->
<section id="iterate">
  <div class="container">
    <h2><span class="section-num">02</span> The Iterate Loop</h2>

    <p>
      Each Worker runs a loop driven by sending itself <code>:iterate</code> messages.
      Here is what happens on each iteration:
    </p>

    <div class="flow-step">
      <div class="flow-num">1</div>
      <div class="flow-body">
        <strong>Guard Check</strong> &mdash; If <code>iteration &ge; max_iterations</code>,
        complete with an error. If history is near capacity, compact it
        (summarize old messages into a single binding).
      </div>
    </div>
    <div class="flow-step">
      <div class="flow-num">2</div>
      <div class="flow-body">
        <strong>LLM Call</strong> &mdash; Call <code>llm_module.chat(history, model, config)</code>
        <em>synchronously</em> from inside <code>handle_info(:iterate)</code>.
        The LLM returns a structured JSON response with <code>reasoning</code> and <code>code</code> fields.
      </div>
    </div>
    <div class="flow-step">
      <div class="flow-num">3</div>
      <div class="flow-body">
        <strong>Branch</strong> &mdash; If <code>code</code> is non-empty, spawn an async eval process
        (see next section). If empty, append a "no code" feedback message to history
        and loop back to step 1.
      </div>
    </div>
    <div class="flow-step">
      <div class="flow-num">4</div>
      <div class="flow-body">
        <strong>Eval Complete</strong> &mdash; When the eval process finishes, it sends
        <code>{:eval_complete, result}</code> back to the Worker. The Worker checks whether
        <code>final_answer</code> was set in the updated bindings.
      </div>
    </div>
    <div class="flow-step">
      <div class="flow-num">5</div>
      <div class="flow-body">
        <strong>Complete or Continue</strong> &mdash; If <code>final_answer != nil</code>,
        the Worker completes and sends the result to the caller. Otherwise, it appends
        a structured feedback message (with output, errors, binding snapshots) and
        sends itself <code>:iterate</code> again.
      </div>
    </div>

    <div class="diagram"><span class="label">Iterate Loop State Machine</span>

                         <span class="msg">send(self(), :iterate)</span>
                                <span class="dim">&#9474;</span>
                                <span class="dim">&#9660;</span>
                    <span class="dim">&#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span>
                    <span class="dim">&#9474;</span> <span class="state">:iterate</span>       <span class="dim">&#9474;</span>
                    <span class="dim">&#9474;</span>  guard check   <span class="dim">&#9474;</span>
                    <span class="dim">&#9474;</span>  LLM call      <span class="dim">&#9474;</span>
                    <span class="dim">&#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span>
                         <span class="dim">&#9474;</span>       <span class="dim">&#9474;</span>
                 <span class="dim">code != ""</span>   <span class="dim">code == ""</span>
                         <span class="dim">&#9474;</span>       <span class="dim">&#9492;&#9472;&#9472;&#9472;</span> <span class="action">append feedback, loop</span> <span class="dim">&#9472;&#9472;&#9488;</span>
                         <span class="dim">&#9660;</span>                                  <span class="dim">&#9474;</span>
              <span class="dim">&#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span>                        <span class="dim">&#9474;</span>
              <span class="dim">&#9474;</span> <span class="action">spawn eval</span>        <span class="dim">&#9474;</span>                        <span class="dim">&#9474;</span>
              <span class="dim">&#9474;</span> <span class="state">Worker returns</span>    <span class="dim">&#9474;</span>  <span class="dim">&larr; mailbox free</span>         <span class="dim">&#9474;</span>
              <span class="dim">&#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span>                        <span class="dim">&#9474;</span>
                         <span class="dim">&#9474;</span>                                  <span class="dim">&#9474;</span>
              <span class="msg">{:eval_complete, result}</span>                       <span class="dim">&#9474;</span>
                         <span class="dim">&#9474;</span>                                  <span class="dim">&#9474;</span>
                         <span class="dim">&#9660;</span>                                  <span class="dim">&#9474;</span>
           <span class="state">final_answer?</span> <span class="dim">&#9472;&#9472; no &#9472;&#9472;&#9472;</span> <span class="action">append feedback</span> <span class="dim">&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span>
                  <span class="dim">&#9474;</span>
                 <span class="dim">yes</span>
                  <span class="dim">&#9474;</span>
                  <span class="dim">&#9660;</span>
            <span class="action">complete()</span>
         <span class="msg">send caller {:rlm_result}</span></div>
  </div>
</section>

<!-- ================================================================== -->
<!-- SECTION 3: THE DEADLOCK PROBLEM -->
<!-- ================================================================== -->
<section id="deadlock">
  <div class="container">
    <h2><span class="section-num">03</span> The Deadlock Problem &amp; Async Eval</h2>

    <p>
      This is the <strong>central architectural challenge</strong> of the entire system
      and the reason the Worker has its current shape. Understanding it is essential to
      assessing any alternative.
    </p>

    <h3>The Problem</h3>
    <p>
      A GenServer processes one message at a time. If the Worker calls
      <code>Code.eval_string</code> synchronously inside <code>handle_info(:iterate)</code>,
      the Worker is blocked. But the code being evaluated might call <code>lm_query()</code>,
      which does <code>GenServer.call(worker_pid, {:spawn_subcall, ...})</code>.
      That call goes into the Worker's mailbox&mdash;which isn't being processed.
    </p>

    <div class="callout deadlock">
      <div class="callout-title">Deadlock Scenario</div>
      <div class="diagram" style="border: none; padding: 12px 0; margin: 0;"><span class="proc">Worker</span>: handle_info(:iterate)
        <span class="dim">&#9492;&#9472;&#9472;</span> <span class="action">LLM call</span> <span class="dim">(ok, returns)</span>
        <span class="dim">&#9492;&#9472;&#9472;</span> <span class="warn">Code.eval_string(code)</span>  <span class="dim">&larr; BLOCKED HERE</span>
              <span class="dim">&#9492;&#9472;&#9472;</span> code calls <span class="fn">lm_query("sub task")</span>
              <span class="dim">&#9492;&#9472;&#9472;</span> <span class="msg">GenServer.call(worker, {:spawn_subcall, ...})</span>
                    <span class="dim">&#9492;&#9472;&#9472;</span> <span class="warn">Message sits in Worker's mailbox</span>
                    <span class="dim">&#9492;&#9472;&#9472;</span> <span class="warn">Worker can't process it (stuck in code execution)</span>
                    <span class="dim">&#9492;&#9472;&#9472;</span> <span class="warn">GenServer.call waits forever</span>
                    <span class="dim">&#9492;&#9472;&#9472;</span> <span class="warn">Code execution can't finish (waiting for subcall)</span>
                    <span class="dim">&#9492;&#9472;&#9472;</span> <span class="warn">DEADLOCK</span></div>
    </div>

    <h3>The Solution: Spawn Eval in a Separate Process</h3>
    <p>
      Instead of running <code>Code.eval_string</code> inside the GenServer callback,
      the Worker <code>spawn</code>s a new process for code execution. The
      <code>handle_info(:iterate)</code> callback returns immediately with
      <code>{:noreply, state}</code>, freeing the Worker's mailbox.
    </p>

    <div class="diagram"><span class="label">How Async Eval Prevents Deadlock</span>

<span class="dim">Time &rarr;</span>

<span class="proc">Worker</span>:     <span class="dim">[</span><span class="state">handle_info :iterate</span><span class="dim">]</span> <span class="dim">[</span><span class="action">LLM call</span><span class="dim">]</span> <span class="dim">[</span><span class="action">spawn eval</span><span class="dim">]</span> <span class="dim">[</span><span class="state">IDLE</span><span class="dim">]</span> <span class="dim">&larr; mailbox processing</span>
                                                       <span class="dim">&#9474;</span>
<span class="proc">Eval</span>:                                                  <span class="dim">[</span><span class="action">Code.eval_string</span><span class="dim">]</span>
                                                       <span class="dim">&#9474;</span>         <span class="dim">&#9474;</span>
                                                       <span class="dim">&#9474;</span>     <span class="fn">lm_query()</span>
                                                       <span class="dim">&#9474;</span>         <span class="dim">&#9474;</span>
                                                       <span class="dim">&#9474;</span>     <span class="msg">GenServer.call(worker, {:spawn_subcall})</span>
                                                       <span class="dim">&#9474;</span>         <span class="dim">&#9474;</span>
<span class="proc">Worker</span>:                                                <span class="dim">[</span><span class="state">handle_call {:spawn_subcall}</span><span class="dim">]</span>
                                                       <span class="dim">&#9474;</span>     <span class="action">spawns child, stores from</span>
                                                       <span class="dim">&#9474;</span>     <span class="dim">{:noreply} &larr; eval still blocked on call</span>
                                                       <span class="dim">&#9474;</span>
<span class="proc">Child</span>:                                                 <span class="dim">[</span><span class="action">own iterate loop...</span><span class="dim">]</span>
                                                       <span class="dim">&#9474;</span>         <span class="dim">&#9474;</span>
                                                       <span class="dim">&#9474;</span>     <span class="msg">{:rlm_result, child_span_id, result}</span>
                                                       <span class="dim">&#9474;</span>         <span class="dim">&#9474;</span>
<span class="proc">Worker</span>:                                                <span class="dim">[</span><span class="state">handle_info {:rlm_result}</span><span class="dim">]</span>
                                                       <span class="dim">&#9474;</span>     <span class="action">GenServer.reply(from, result)</span>
                                                       <span class="dim">&#9474;</span>         <span class="dim">&#9474;</span>
<span class="proc">Eval</span>:                                                  <span class="dim">&#9474;</span>     <span class="action">lm_query() returns</span>
                                                       <span class="dim">&#9474;</span>     <span class="action">eval continues</span>
                                                       <span class="dim">&#9474;</span>     <span class="action">eval finishes</span>
                                                       <span class="dim">&#9474;</span>
                                                       <span class="msg">{:eval_complete, result}</span>
                                                       <span class="dim">&#9474;</span>
<span class="proc">Worker</span>:                                                <span class="dim">[</span><span class="state">handle_info {:eval_complete}</span><span class="dim">]</span></div>

    <h3>The <code>eval_context</code> Bridge</h3>
    <p>
      When the Worker spawns code execution, it needs to remember context about the current
      iteration (what code was sent, the LLM's reasoning, timing data) so it can
      process the result when <code>{:eval_complete, ...}</code> arrives. This context
      is stored in <code>state.eval_context</code>:
    </p>
    <pre class="code"><code><span class="cm">%{</span>
  <span class="at">code:</span> <span class="str">"x = 1 + 1\nfinal_answer = x"</span>,
  <span class="at">reasoning:</span> <span class="str">"I'll compute the sum..."</span>,
  <span class="at">assistant_msg:</span> <span class="cm">%{role: :assistant, content: json_response}</span>,
  <span class="at">llm_duration:</span> <span class="num">1200</span>,
  <span class="at">usage:</span> <span class="cm">%{input_tokens: 500, output_tokens: 80}</span>,
  <span class="at">iter_start:</span> <span class="num">-576460751</span>,
  <span class="at">code_start:</span> <span class="num">-576460750</span>
<span class="cm">}</span></code></pre>
    <p>
      When <code>eval_context</code> is <code>nil</code>, no code execution is in flight.
      When it holds a map, the Worker knows to expect an <code>{:eval_complete, ...}</code>
      message.
    </p>
  </div>
</section>

<!-- ================================================================== -->
<!-- SECTION 4: SUBCALLS -->
<!-- ================================================================== -->
<section id="subcalls">
  <div class="container">
    <h2><span class="section-num">04</span> Recursive Subcalls</h2>

    <p>
      When code being evaluated calls <code>lm_query("some task")</code>, the following
      multi-process dance occurs. This is the heart of the recursion.
    </p>

    <h3>The Three Key Data Structures</h3>

    <table>
      <thead>
        <tr>
          <th>Structure</th>
          <th>Type</th>
          <th>Purpose</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>pending_subcalls</code></td>
          <td><code>%{id =&gt; GenServer.from()}</code></td>
          <td>Maps child span_id (or query_id) to the blocked code execution process's reply handle.
              When the child finishes, the Worker uses this to unblock the code execution.</td>
        </tr>
        <tr>
          <td><code>pending_monitors</code></td>
          <td><code>%{reference() =&gt; span_id}</code></td>
          <td>Maps Process.monitor refs to child span_ids. Used by the
              <code>{:DOWN, ...}</code> handler to find which subcall crashed.</td>
        </tr>
        <tr>
          <td><code>GenServer.from()</code></td>
          <td><code>{pid, tag}</code></td>
          <td>An opaque handle that GenServer uses for delayed replies. Stored when
              <code>handle_call</code> returns <code>{:noreply, ...}</code>, used later
              with <code>GenServer.reply/2</code>.</td>
        </tr>
      </tbody>
    </table>

    <h3>Step-by-Step Flow</h3>

    <div class="diagram"><span class="label">Subcall: Eval &rarr; Worker &rarr; Child Worker &rarr; Worker &rarr; Eval</span>

<span class="proc">Eval Process</span>                    <span class="proc">Parent Worker</span>                  <span class="proc">Child Worker</span>
<span class="dim">&#9474;</span>                                <span class="dim">&#9474;</span>                              <span class="dim">&#9474;</span>
<span class="fn">lm_query("task")</span>                 <span class="dim">&#9474;</span>                              <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                                <span class="dim">&#9474;</span>                              <span class="dim">&#9474;</span>
<span class="msg">GenServer.call(worker,</span>  <span class="dim">&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&rarr;</span> <span class="state">handle_call</span>                    <span class="dim">&#9474;</span>
<span class="msg">  {:spawn_subcall})</span>              <span class="dim">&#9474;</span>                              <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                              <span class="action">depth check</span> <span class="dim">(ok)</span>                <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                              <span class="action">concurrency check</span> <span class="dim">(ok)</span>           <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                              <span class="action">DynamicSupervisor.start_child</span> <span class="dim">&rarr;</span> <span class="action">init</span>
<span class="dim">&#9474;</span>                              <span class="action">Process.monitor(child_pid)</span>     <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                              <span class="action">store from in pending_subcalls</span> <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                              <span class="action">store ref in pending_monitors</span>  <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                              <span class="dim">{:noreply, state}</span>              <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                                <span class="dim">&#9474;</span>                            <span class="state">iterate loop...</span>
<span class="warn">BLOCKED</span> <span class="dim">(waiting for reply)</span>     <span class="dim">&#9474;</span>                            <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                                <span class="dim">&#9474;</span>                            <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                                <span class="dim">&#9474;</span>                            <span class="action">final_answer set</span>
<span class="dim">&#9474;</span>                                <span class="dim">&#9474;</span>                <span class="msg">&larr;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;</span> <span class="msg">{:rlm_result, child_id, result}</span>
<span class="dim">&#9474;</span>                              <span class="state">handle_info {:rlm_result}</span>       <span class="dim">&#9474;</span>
<span class="dim">&#9474;</span>                              <span class="action">pop pending_subcalls</span>           <span class="action">{:stop, :normal}</span>
<span class="dim">&#9474;</span>                              <span class="action">demonitor child</span>
<span class="dim">&#9474;</span>                <span class="msg">&larr;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;</span> <span class="action">GenServer.reply(from, result)</span>
<span class="dim">&#9474;</span>
<span class="fn">lm_query returns</span> <span class="dim">{:ok, answer}</span>
<span class="action">code execution continues...</span></div>

    <h3>Crash Recovery</h3>
    <p>
      If the child Worker crashes before sending <code>{:rlm_result, ...}</code>,
      the parent receives a <code>{:DOWN, ref, :process, pid, reason}</code> message.
      The handler uses <code>pending_monitors</code> to find the child's span_id,
      looks up the blocked code execution process's <code>from</code> in <code>pending_subcalls</code>,
      and replies with <code>{:error, "Subcall crashed: ..."}</code>.
    </p>

    <div class="diagram"><span class="label">Crash Recovery Path</span>

<span class="proc">Child Worker</span> <span class="warn">CRASHES</span>
        <span class="dim">&#9474;</span>
        <span class="dim">&#9660;</span>
<span class="msg">{:DOWN, ref, :process, pid, reason}</span> <span class="dim">&rarr;</span> <span class="proc">Parent Worker</span>
        <span class="dim">&#9474;</span>
        <span class="dim">&#9492;&#9472;</span> <span class="action">Map.pop(pending_monitors, ref)</span> <span class="dim">&rarr;</span> <span class="hl">child_span_id</span>
        <span class="dim">&#9492;&#9472;</span> <span class="action">Map.pop(pending_subcalls, child_span_id)</span> <span class="dim">&rarr;</span> <span class="hl">from</span>
        <span class="dim">&#9492;&#9472;</span> <span class="action">GenServer.reply(from, {:error, "Subcall crashed: ..."})</span>
        <span class="dim">&#9492;&#9472;</span> <span class="dim">Eval process receives {:error, ...} and can handle it</span></div>
  </div>
</section>

<!-- ================================================================== -->
<!-- SECTION 5: DIRECT QUERY -->
<!-- ================================================================== -->
<section id="direct-query">
  <div class="container">
    <h2><span class="section-num">05</span> Direct Query (Schema Mode)</h2>

    <p>
      <code>lm_query("extract names", schema: json_schema)</code> takes a fundamentally
      different path. Instead of spawning a child Worker with its own iterate loop,
      it makes a <strong>single LLM call</strong> with the schema as
      <code>output_config</code> and returns the JSON-decoded response.
    </p>

    <div class="comparison">
      <div>
        <h4 style="color: var(--accent);">Regular Subcall</h4>
        <ul style="list-style: none; padding: 0;">
          <li>Full child Worker GenServer</li>
          <li>Own iterate loop (multiple LLM turns)</li>
          <li>System prompt included</li>
          <li>Depth check enforced</li>
          <li>Returns <code>{:ok, string}</code></li>
          <li>Process.monitor for crash handling</li>
        </ul>
      </div>
      <div>
        <h4 style="color: var(--teal);">Direct Query</h4>
        <ul style="list-style: none; padding: 0;">
          <li>Plain <code>spawn</code>'d process</li>
          <li>Single LLM call, no iteration</li>
          <li>No system prompt</li>
          <li>No depth check (leaf operation)</li>
          <li>Returns <code>{:ok, %{parsed: "map"}}</code></li>
          <li>No monitor (relies on timeout)</li>
        </ul>
      </div>
    </div>

    <div class="callout insight">
      <div class="callout-title">Design Rationale</div>
      Direct queries exist because many sub-tasks don't need recursive reasoning. Entity
      extraction, classification, or data parsing are single-shot operations. A full
      iterate loop with a system prompt would be wasteful. The schema constraint guarantees
      structured output, eliminating the need for "code that processes the response."
    </div>
  </div>
</section>

<!-- ================================================================== -->
<!-- SECTION 6: FULL MESSAGE FLOW -->
<!-- ================================================================== -->
<section id="message-flow">
  <div class="container">
    <h2><span class="section-num">06</span> Complete Message Flow</h2>

    <p>
      This diagram traces every message in a complete execution where a parent Worker's
      code spawns one subcall.
    </p>

    <div class="diagram"><span class="label">End-to-End Message Flow: RLM.run with One Subcall</span>

<span class="proc">Caller</span>              <span class="proc">Worker A</span>             <span class="proc">Eval Proc</span>          <span class="proc">Worker B</span>
<span class="dim">  &#9474;</span>                      <span class="dim">&#9474;</span>                     <span class="dim">&#9474;</span>                   <span class="dim">&#9474;</span>
  <span class="action">RLM.run/3</span>
  <span class="dim">&#9474;</span>
  <span class="action">DynSup.start_child</span> <span class="dim">&rarr;</span> <span class="action">init()</span>
  <span class="action">Process.monitor</span>        <span class="msg">send(self, :iterate)</span>
  <span class="dim">&#9474;</span>                      <span class="dim">&#9474;</span>
  <span class="warn">BLOCKED in</span>             <span class="state">handle_info(:iterate)</span>
  <span class="warn">receive</span>                <span class="dim">&#9474;</span>
  <span class="dim">&#9474;</span>                      <span class="action">LLM.chat()</span> <span class="dim">(sync, returns)</span>
  <span class="dim">&#9474;</span>                      <span class="action">extract_structured()</span>
  <span class="dim">&#9474;</span>                      <span class="action">spawn eval</span> <span class="dim">&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&rarr;</span> <span class="action">Code.eval_string</span>
  <span class="dim">&#9474;</span>                      <span class="dim">{:noreply}</span>              <span class="dim">&#9474;</span>
  <span class="dim">&#9474;</span>                      <span class="dim">&#9474;</span>                     <span class="fn">lm_query("sub")</span>
  <span class="dim">&#9474;</span>                      <span class="dim">&#9474;</span>              <span class="msg">&larr;&#9472;&#9472;&#9472;&#9472;</span> <span class="msg">call {:spawn_subcall}</span>
  <span class="dim">&#9474;</span>                      <span class="state">handle_call</span>            <span class="warn">BLOCKED</span>
  <span class="dim">&#9474;</span>                      <span class="action">start_child</span> <span class="dim">&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&rarr;</span> <span class="action">init()</span>
  <span class="dim">&#9474;</span>                      <span class="action">monitor, store from</span>    <span class="dim">&#9474;</span>              <span class="msg">send(:iterate)</span>
  <span class="dim">&#9474;</span>                      <span class="dim">{:noreply}</span>              <span class="dim">&#9474;</span>              <span class="state">handle_info</span>
  <span class="dim">&#9474;</span>                      <span class="dim">&#9474;</span>                     <span class="dim">&#9474;</span>              <span class="action">LLM + eval</span>
  <span class="dim">&#9474;</span>                      <span class="dim">&#9474;</span>                     <span class="dim">&#9474;</span>              <span class="dim">  ...</span>
  <span class="dim">&#9474;</span>                      <span class="dim">&#9474;</span>                     <span class="dim">&#9474;</span>              <span class="action">complete()</span>
  <span class="dim">&#9474;</span>                      <span class="dim">&#9474;</span>                     <span class="dim">&#9474;</span>       <span class="msg">&larr;&#9472;&#9472;&#9472;&#9472;</span> <span class="msg">{:rlm_result, B, val}</span>
  <span class="dim">&#9474;</span>                      <span class="state">handle_info</span>            <span class="dim">&#9474;</span>              <span class="action">{:stop}</span>
  <span class="dim">&#9474;</span>                      <span class="action">GenServer.reply(from)</span> <span class="dim">&rarr;</span> <span class="action">lm_query returns</span>
  <span class="dim">&#9474;</span>                      <span class="dim">&#9474;</span>                     <span class="action">eval continues</span>
  <span class="dim">&#9474;</span>                      <span class="dim">&#9474;</span>                     <span class="action">final_answer = ...</span>
  <span class="dim">&#9474;</span>                      <span class="dim">&#9474;</span>              <span class="msg">&larr;&#9472;&#9472;&#9472;&#9472;</span> <span class="msg">{:eval_complete, result}</span>
  <span class="dim">&#9474;</span>                      <span class="state">handle_info</span>
  <span class="dim">&#9474;</span>                      <span class="action">final_answer set</span>
  <span class="dim">&#9474;</span>               <span class="msg">&larr;&#9472;&#9472;&#9472;</span> <span class="msg">{:rlm_result, A, answer}</span>
  <span class="dim">&#9474;</span>                      <span class="action">{:stop, :normal}</span>
  <span class="action">receive matches</span>
  <span class="action">{:ok, answer, run_id}</span></div>

    <div class="callout key">
      <div class="callout-title">Process Count</div>
      A single <code>RLM.run/3</code> with one subcall involves <strong>4 Erlang processes</strong>:
      the Caller, Worker A (GenServer), an Eval process (short-lived spawn), and Worker B
      (GenServer). If Worker B's code also spawns a subcall, add 2 more processes
      (another Eval + Worker C). The process count is <code>1 + 2N</code> where N is the
      total number of Workers in the tree.
    </div>
  </div>
</section>

<!-- ================================================================== -->
<!-- SECTION 7: OTP ANALYSIS -->
<!-- ================================================================== -->
<section id="otp">
  <div class="container">
    <h2><span class="section-num">07</span> OTP Conformity Analysis</h2>

    <p>
      How well does this architecture use OTP patterns? Let's assess each aspect.
    </p>

    <h3>What's Idiomatic</h3>
    <div class="card-grid">
      <div class="card pro">
        <h4><span class="tag tag-otp">OTP</span> DynamicSupervisor for Workers</h4>
        <p>Workers are started on demand, registered via Registry, and use
        <code>restart: :temporary</code>. This is textbook DynamicSupervisor usage.</p>
      </div>
      <div class="card pro">
        <h4><span class="tag tag-otp">OTP</span> Registry for Name Resolution</h4>
        <p>Using <code>{:via, Registry, ...}</code> tuples keeps PIDs out of application
        code. Workers and EventLogs are addressed by span_id/run_id, not PIDs.</p>
      </div>
      <div class="card pro">
        <h4><span class="tag tag-otp">OTP</span> Process.monitor for Crash Detection</h4>
        <p>The parent monitors child Workers and cleans up gracefully on crash.
        The caller monitors the root Worker. Standard OTP crash propagation.</p>
      </div>
      <div class="card pro">
        <h4><span class="tag tag-otp">OTP</span> Telemetry Integration</h4>
        <p>Events flow through <code>:telemetry</code> to decoupled handlers for
        logging, persistence, and PubSub. No tight coupling between Worker and
        observability.</p>
      </div>
    </div>

    <h3>What's Non-Standard</h3>
    <div class="card-grid">
      <div class="card con">
        <h4><span class="tag tag-otp">OTP</span> Flat Supervision for Tree Structure</h4>
        <p>Workers form a logical tree (parent-child recursion) but are supervised
        as flat siblings. OTP can't automatically clean up a subtree if a parent
        crashes&mdash;orphaned children continue running until their iterate loop
        finishes or times out. A supervisor-per-subtree pattern would be more native.</p>
      </div>
      <div class="card con">
        <h4><span class="tag tag-otp">OTP</span> Manual State Machine in GenServer</h4>
        <p>The Worker tracks states (<code>:running</code>, <code>:idle</code>,
        <code>eval_context</code> presence) manually. OTP provides <code>:gen_statem</code>
        for exactly this pattern, with built-in state transition enforcement and
        per-state timeouts.</p>
      </div>
      <div class="card con">
        <h4><span class="tag tag-otp">OTP</span> Bare <code>spawn</code> for Eval</h4>
        <p>Eval processes are spawned with <code>spawn/1</code>, not
        <code>Task.Supervisor.async</code> or a supervised process. If the eval process
        leaks (e.g., timeout race), there's no automatic cleanup. The Worker does use
        <code>spawn_monitor</code> inside <code>RLM.Eval.run</code>, but the outer
        spawn from <code>start_async_eval</code> is unmonitored.</p>
      </div>
      <div class="card con">
        <h4><span class="tag tag-otp">OTP</span> Process Dictionary for State Passing</h4>
        <p>The eval process uses <code>Process.put/get</code> to pass
        <code>worker_pid</code>, <code>subcall_timeout</code>, and <code>cwd</code> into
        sandbox functions. This is an OTP anti-pattern&mdash;process dictionary makes
        dependencies invisible and testing harder. A closure or module attribute would
        be more explicit.</p>
      </div>
    </div>

    <h3>Scores</h3>
    <div class="verdict-grid">
      <div class="verdict-item">
        <div class="score high">7</div>
        <div class="label">Supervision</div>
      </div>
      <div class="verdict-item">
        <div class="score mid">5</div>
        <div class="label">State Mgmt</div>
      </div>
      <div class="verdict-item">
        <div class="score high">8</div>
        <div class="label">Registration</div>
      </div>
      <div class="verdict-item">
        <div class="score mid">6</div>
        <div class="label">Process Lifecycle</div>
      </div>
    </div>
  </div>
</section>

<!-- ================================================================== -->
<!-- SECTION 8: PROS -->
<!-- ================================================================== -->
<section id="pros">
  <div class="container">
    <h2><span class="section-num">08</span> Pros of the Current Architecture</h2>

    <div class="card-grid">
      <div class="card pro">
        <h4><span class="tag tag-perf">PERF</span> True Concurrent Subcalls</h4>
        <p>Multiple <code>lm_query()</code> calls from a single evaluation can run in parallel
        via <code>parallel_query</code>. Each spawns an independent Worker or LLM call.
        The parent Worker processes all their results as they arrive. This is natural
        concurrency without any explicit threading model.</p>
      </div>
      <div class="card pro">
        <h4><span class="tag tag-error">ERROR</span> Graceful Degradation</h4>
        <p>A crashed child doesn't crash the parent. The monitor fires, the code execution gets
        an error tuple, and the LLM can reason about the failure and try a different
        approach. The system is resilient by default.</p>
      </div>
      <div class="card pro">
        <h4><span class="tag tag-legibility">READ</span> Single Point of State</h4>
        <p>All state for a node lives in one GenServer's state struct: history, bindings,
        pending subcalls, iteration count, eval context. There's one place to look when
        debugging, one place to inspect at runtime.</p>
      </div>
      <div class="card pro">
        <h4><span class="tag tag-maintenance">MAINT</span> Clean Separation of Concerns</h4>
        <p><code>Worker</code> = orchestration, <code>Eval</code> = execution,
        <code>Sandbox</code> = API surface, <code>LLM</code> = external calls,
        <code>Prompt</code> = message formatting. Each module has a clear,
        single responsibility.</p>
      </div>
      <div class="card pro">
        <h4><span class="tag tag-otp">OTP</span> Testability via Dependency Injection</h4>
        <p>The <code>llm_module</code> config field swaps in <code>MockLLM</code> for
        tests. Workers, eval, and subcalls all exercise real OTP machinery with
        deterministic LLM responses. No mocking frameworks needed.</p>
      </div>
      <div class="card pro">
        <h4><span class="tag tag-legibility">READ</span> Persistent REPL Semantics</h4>
        <p>Bindings carry across iterations and turns (in keep-alive mode). Variables set
        in iteration 1 are available in iteration 5. This gives the LLM a genuine
        stateful programming environment, not just independent code snippets.</p>
      </div>
    </div>
  </div>
</section>

<!-- ================================================================== -->
<!-- SECTION 9: CONS -->
<!-- ================================================================== -->
<section id="cons">
  <div class="container">
    <h2><span class="section-num">09</span> Cons and Complexity Costs</h2>

    <div class="card-grid">
      <div class="card con">
        <h4><span class="tag tag-complexity">CPLX</span> The <code>handle_info</code> Dispatch Table</h4>
        <p><code>Worker.handle_info/2</code> handles at least 6 different message types:
        <code>:iterate</code>, <code>{:eval_complete, ...}</code>,
        <code>{:rlm_result, ...}</code>, <code>{:direct_query_result, ...}</code>,
        <code>{:DOWN, ...}</code>, and <code>:timeout</code>. Combined with
        <code>handle_call</code> clauses for <code>:spawn_subcall</code>,
        <code>:direct_query</code>, <code>:send_message</code>, <code>:history</code>,
        and <code>:status</code>, the Worker module is over 800 lines. A new contributor
        must understand all message types and their interactions to modify the Worker
        safely.</p>
      </div>
      <div class="card con">
        <h4><span class="tag tag-legibility">READ</span> Invisible Control Flow</h4>
        <p>The execution path jumps between processes via <code>send</code> and
        <code>GenServer.call/reply</code>. Reading the Worker code linearly doesn't reveal
        the actual execution order. You must mentally simulate the async message flow
        across <code>:iterate &rarr; spawn eval &rarr; :eval_complete</code> to understand
        what happens. This is inherent to actor-model concurrency but amplified here by
        the three-process coordination.</p>
      </div>
      <div class="card con">
        <h4><span class="tag tag-error">ERROR</span> Orphaned Processes</h4>
        <p>If a parent Worker crashes, its children continue running under the flat
        DynamicSupervisor. They'll eventually complete or time out, but they're doing
        wasted work. The <code>pending_subcalls</code> map is lost with the parent, so
        nobody receives their results. The eval process that was blocked on
        <code>GenServer.call</code> receives an <code>:EXIT</code> from the linked
        Worker, so it dies, but the child Workers are unlinked peers.</p>
      </div>
      <div class="card con">
        <h4><span class="tag tag-complexity">CPLX</span> Two Maps for One Relationship</h4>
        <p><code>pending_subcalls</code> maps <code>span_id &rarr; from</code>.
        <code>pending_monitors</code> maps <code>ref &rarr; span_id</code>. These
        track the same logical relationship (a pending child) from two different angles.
        A single data structure with composite keys or a struct-per-child would be
        clearer and eliminate the <code>pop_monitor_by_span</code> linear scan.</p>
      </div>
      <div class="card con">
        <h4><span class="tag tag-maintenance">MAINT</span> Eval Context as Implicit State</h4>
        <p><code>eval_context</code> is either <code>nil</code> or a map&mdash;a boolean
        flag masquerading as an optional struct. The Worker's behavior changes based on
        its presence, but this is checked implicitly (the Worker just "knows" to expect
        <code>{:eval_complete, ...}</code> when <code>eval_context</code> is set). A
        state machine would make this transition explicit.</p>
      </div>
      <div class="card con">
        <h4><span class="tag tag-error">ERROR</span> Unmonitored Direct Query Processes</h4>
        <p>Direct queries use <code>spawn/1</code> without <code>Process.monitor</code>.
        If the spawned process crashes between the LLM call and sending
        <code>{:direct_query_result, ...}</code>, the entry in
        <code>pending_subcalls</code> lingers until the eval's
        <code>GenServer.call</code> times out (up to 10 minutes by default).</p>
      </div>
    </div>
  </div>
</section>

<!-- ================================================================== -->
<!-- SECTION 10: ALTERNATIVES -->
<!-- ================================================================== -->
<section id="alternatives">
  <div class="container">
    <h2><span class="section-num">10</span> Alternative Architectures</h2>

    <p>
      Each alternative addresses specific cons of the current design. No alternative is
      strictly better&mdash;each trades some advantages for others. The goal is to
      understand the design space.
    </p>

    <!-- ---- Alt 1: gen_statem ---- -->
    <details open>
      <summary>Alternative 1: gen_statem Worker</summary>
      <div class="content">
        <p><span class="tag tag-otp">OTP</span> <span class="tag tag-legibility">READ</span></p>

        <h4>Core Idea</h4>
        <p>
          Replace the GenServer Worker with a <code>:gen_statem</code> (or
          <code>GenStateMachine</code> wrapper). Make the Worker's implicit states
          explicit: <code>:calling_llm</code>, <code>:waiting_for_eval</code>,
          <code>:waiting_for_subcall</code>, <code>:idle</code>, <code>:done</code>.
        </p>

        <div class="diagram"><span class="label">gen_statem State Transitions</span>

  <span class="state">:calling_llm</span>
       <span class="dim">&#9474;</span>
       <span class="dim">&#9474;</span> <span class="action">LLM response received</span>
       <span class="dim">&#9474;</span>
       <span class="dim">&#9500;&#9472;&#9472;</span> <span class="dim">code == ""</span> <span class="dim">&rarr;</span> <span class="action">append feedback</span> <span class="dim">&rarr;</span> <span class="state">:calling_llm</span> <span class="dim">(loop)</span>
       <span class="dim">&#9474;</span>
       <span class="dim">&#9492;&#9472;&#9472;</span> <span class="dim">code != ""</span> <span class="dim">&rarr;</span> <span class="action">spawn eval</span> <span class="dim">&rarr;</span> <span class="state">:waiting_for_eval</span>
                                            <span class="dim">&#9474;</span>
                          <span class="msg">{:eval_complete}</span> <span class="dim">&rarr;</span> <span class="dim">&#9474;</span>
                                            <span class="dim">&#9474;</span>
                          <span class="dim">final_answer?</span> <span class="dim">&#9472;&#9472;</span> <span class="dim">yes</span> <span class="dim">&rarr;</span> <span class="state">:done</span>
                                            <span class="dim">&#9474;</span>
                                           <span class="dim">no</span> <span class="dim">&rarr;</span> <span class="state">:calling_llm</span>

  <span class="cm">In :waiting_for_eval, subcall messages are handled as</span>
  <span class="cm">state-specific callbacks (not generic handle_info).</span></div>

        <div class="comparison">
          <div style="border-left: 3px solid var(--green);">
            <h4 style="color: var(--green);">Advantages</h4>
            <ul style="padding-left: 18px;">
              <li><strong>Invalid messages rejected by state:</strong> A <code>:send_message</code>
                  in <code>:waiting_for_eval</code> is automatically rejected without manual
                  guards.</li>
              <li><strong>Per-state timeouts:</strong> <code>:gen_statem</code> has built-in
                  state timeouts. The LLM call, eval, and subcall phases each get their own
                  timeout, replacing the manual <code>eval_timeout</code> / <code>subcall_timeout</code>
                  logic.</li>
              <li><strong>Auditable transitions:</strong> The state machine is self-documenting.
                  A reviewer can read the state diagram and know exactly what messages are
                  valid in each phase.</li>
              <li><strong>Eliminates <code>eval_context</code>:</strong> State data is part of the
                  state callback data, scoped to the state that uses it.</li>
            </ul>
          </div>
          <div style="border-left: 3px solid var(--red);">
            <h4 style="color: var(--red);">Disadvantages</h4>
            <ul style="padding-left: 18px;">
              <li><strong>Elixir ecosystem unfamiliarity:</strong> <code>:gen_statem</code> is
                  rarely used in Elixir. Most developers know GenServer but not gen_statem.
                  The learning curve for contributors increases.</li>
              <li><strong>Verbose callback structure:</strong> Each state needs its own
                  callback clause for every message type. With 6+ message types and 4+ states,
                  the combinatorial explosion creates more code, not less.</li>
              <li><strong>Subcalls complicate the state model:</strong> The Worker must handle
                  subcall spawn/result messages <em>while also</em> waiting for eval. This
                  means <code>:waiting_for_eval</code> must handle the same subcall messages
                  as any other state, partially defeating the purpose of distinct states.</li>
              <li><strong>Harder to test:</strong> Testing state machines requires driving
                  the machine through specific state sequences. The current GenServer tests
                  are simpler because they just send messages and check responses.</li>
            </ul>
          </div>
        </div>
      </div>
    </details>

    <!-- ---- Alt 2: Coordinator + Runner ---- -->
    <details>
      <summary>Alternative 2: Split Coordinator + Runner Processes</summary>
      <div class="content">
        <p><span class="tag tag-legibility">READ</span> <span class="tag tag-maintenance">MAINT</span></p>

        <h4>Core Idea</h4>
        <p>
          Split the Worker into two processes: a <strong>Coordinator</strong> (GenServer) that
          manages state, subcalls, and control flow, and a <strong>Runner</strong> (Task or
          supervised process) that handles the synchronous LLM call + eval sequence. The
          Coordinator never blocks; the Runner always blocks.
        </p>

        <div class="diagram"><span class="label">Coordinator + Runner Split</span>

<span class="proc">Coordinator</span> <span class="dim">(GenServer, always responsive)</span>
  <span class="dim">&#9474;</span>
  <span class="dim">&#9500;&#9472;</span> <span class="action">Starts Runner for each iteration</span>
  <span class="dim">&#9500;&#9472;</span> <span class="action">Handles {:spawn_subcall} from Runner</span>
  <span class="dim">&#9500;&#9472;</span> <span class="action">Handles {:rlm_result} from children</span>
  <span class="dim">&#9500;&#9472;</span> <span class="action">Replies to Runner when subcall completes</span>
  <span class="dim">&#9492;&#9472;</span> <span class="action">Owns state: history, bindings, pending_subcalls</span>

<span class="proc">Runner</span> <span class="dim">(Task/Process, one per iteration, may block)</span>
  <span class="dim">&#9474;</span>
  <span class="dim">&#9500;&#9472;</span> <span class="action">Calls LLM (synchronous)</span>
  <span class="dim">&#9500;&#9472;</span> <span class="action">Runs Code.eval_string (synchronous)</span>
  <span class="dim">&#9492;&#9472;</span> <span class="action">Sends result back to Coordinator</span></div>

        <div class="comparison">
          <div style="border-left: 3px solid var(--green);">
            <h4 style="color: var(--green);">Advantages</h4>
            <ul style="padding-left: 18px;">
              <li><strong>Eliminates the async-eval pattern:</strong> The deadlock doesn't exist
                  because the Coordinator never runs eval. The Runner can block freely; subcall
                  requests go to the Coordinator, which is always idle.</li>
              <li><strong>Coordinator is simple:</strong> It just manages state and dispatches
                  messages. No LLM calls, no eval, no timing. Easy to audit.</li>
              <li><strong>Runner is simple:</strong> It just runs the sequential
                  LLM &rarr; eval pipeline. No GenServer callbacks, no state management.</li>
              <li><strong>Natural supervision:</strong> The Runner can be a supervised Task
                  under a Task.Supervisor, getting automatic monitoring for free.</li>
            </ul>
          </div>
          <div style="border-left: 3px solid var(--red);">
            <h4 style="color: var(--red);">Disadvantages</h4>
            <ul style="padding-left: 18px;">
              <li><strong>Two processes per node:</strong> Doubles the process count per
                  Worker. For deep recursion trees, this can add up.</li>
              <li><strong>State synchronization:</strong> Bindings and history must flow
                  between Coordinator and Runner on every iteration. This is either
                  message-passing overhead or shared ETS, both of which add complexity.</li>
              <li><strong>The Runner still needs the Coordinator's PID:</strong>
                  <code>lm_query()</code> in code being evaluated must call the Coordinator, not the
                  Runner. This requires the same process-dictionary injection as today.</li>
              <li><strong>More moving parts:</strong> Debugging requires tracing two
                  cooperating processes instead of one. The message flow has more hops.</li>
            </ul>
          </div>
        </div>
      </div>
    </details>

    <!-- ---- Alt 3: Continuation ---- -->
    <details>
      <summary>Alternative 3: Continuation-Passing (No Concurrent Eval)</summary>
      <div class="content">
        <p><span class="tag tag-legibility">READ</span> <span class="tag tag-error">ERROR</span></p>

        <h4>Core Idea</h4>
        <p>
          Eliminate the need for concurrent processes entirely. Instead of code calling
          <code>lm_query()</code> and blocking, it returns a special token:
          <code>{:subcall_needed, text, continuation_fn}</code>. The Worker processes
          the subcall, then invokes the continuation with the result.
        </p>

        <div class="diagram"><span class="label">Continuation-Based Flow</span>

<span class="proc">Worker</span> <span class="dim">(single process, no concurrency)</span>
  <span class="dim">&#9474;</span>
  <span class="state">:iterate</span>
  <span class="dim">&#9474;</span>
  <span class="action">LLM call</span> <span class="dim">(sync)</span>
  <span class="dim">&#9474;</span>
  <span class="action">run code</span>
  <span class="dim">&#9474;</span>
  <span class="dim">&#9500;&#9472;&#9472;</span> <span class="dim">returns {:ok, final_answer}</span> <span class="dim">&rarr;</span> <span class="action">complete</span>
  <span class="dim">&#9474;</span>
  <span class="dim">&#9500;&#9472;&#9472;</span> <span class="dim">returns {:subcall, text, cont_fn}</span>
  <span class="dim">&#9474;</span>       <span class="dim">&#9474;</span>
  <span class="dim">&#9474;</span>       <span class="action">spawn child Worker for subcall</span>
  <span class="dim">&#9474;</span>       <span class="dim">&#9474;</span>
  <span class="dim">&#9474;</span>       <span class="msg">receive {:rlm_result, result}</span>
  <span class="dim">&#9474;</span>       <span class="dim">&#9474;</span>
  <span class="dim">&#9474;</span>       <span class="action">cont_fn.(result)</span>  <span class="dim">&larr; resume code with result</span>
  <span class="dim">&#9474;</span>
  <span class="dim">&#9492;&#9472;&#9472;</span> <span class="dim">returns {:continue, bindings}</span> <span class="dim">&rarr;</span> <span class="state">:iterate</span></div>

        <div class="comparison">
          <div style="border-left: 3px solid var(--green);">
            <h4 style="color: var(--green);">Advantages</h4>
            <ul style="padding-left: 18px;">
              <li><strong>No deadlock possible:</strong> Only one process. No concurrent
                  mailbox contention. The entire flow is sequential.</li>
              <li><strong>Easy to trace:</strong> Execution is linear. You can read the code
                  top-to-bottom and understand exactly what happens.</li>
              <li><strong>No <code>pending_subcalls</code>:</strong> The continuation holds
                  the "what to do next" directly. No map lookups, no <code>from</code>
                  management.</li>
              <li><strong>Simpler error handling:</strong> A crashed subcall can be caught
                  directly in the Worker's receive, and the continuation can be invoked
                  with an error tuple.</li>
            </ul>
          </div>
          <div style="border-left: 3px solid var(--red);">
            <h4 style="color: var(--red);">Disadvantages</h4>
            <ul style="padding-left: 18px;">
              <li><strong>No parallel subcalls:</strong> Only one subcall can run at a time.
                  <code>parallel_query</code> becomes impossible or requires a mini-coordinator
                  that reintroduces the concurrency complexity.</li>
              <li><strong>Breaks the REPL contract:</strong> <code>Code.eval_string</code>
                  doesn't support continuations. The LLM's code can't just call
                  <code>lm_query()</code> and use the result on the next line. You'd need a
                  custom interpreter or code transformation step.</li>
              <li><strong>LLM code becomes less natural:</strong> Instead of writing
                  <code>result = lm_query("...")</code>, the LLM must write
                  continuation-style code or the system must split code at subcall boundaries.
                  This adds a code transformation layer and makes the LLM's task harder.</li>
              <li><strong>Closures over bindings are fragile:</strong> The continuation
                  function captures the binding context. Serializing and resuming
                  this state correctly is non-trivial in Elixir.</li>
            </ul>
          </div>
        </div>
      </div>
    </details>

    <!-- ---- Alt 4: Supervisor-per-subtree ---- -->
    <details>
      <summary>Alternative 4: Supervisor-Per-Subtree</summary>
      <div class="content">
        <p><span class="tag tag-otp">OTP</span> <span class="tag tag-error">ERROR</span></p>

        <h4>Core Idea</h4>
        <p>
          Instead of all Workers being flat siblings under one DynamicSupervisor,
          each Worker gets its own DynamicSupervisor for its children. When a parent
          dies, its supervisor (and all children) die automatically.
        </p>

        <div class="diagram"><span class="label">Current vs. Supervisor-Per-Subtree</span>

<span class="hl">CURRENT (Flat):</span>

<span class="proc">RLM.WorkerSup</span>
  <span class="dim">&#9500;&#9472;&#9472;</span> <span class="proc">Worker A</span> <span class="dim">(depth=0)</span>
  <span class="dim">&#9500;&#9472;&#9472;</span> <span class="proc">Worker B</span> <span class="dim">(depth=1, child of A)</span>
  <span class="dim">&#9492;&#9472;&#9472;</span> <span class="proc">Worker C</span> <span class="dim">(depth=2, child of B)</span>

<span class="dim">If A crashes, B and C continue as orphans.</span>

<span class="hl">ALTERNATIVE (Nested):</span>

<span class="proc">RLM.WorkerSup</span>
  <span class="dim">&#9492;&#9472;&#9472;</span> <span class="proc">Worker A</span> + <span class="proc">A.ChildSup</span> <span class="dim">(DynamicSupervisor)</span>
        <span class="dim">&#9492;&#9472;&#9472;</span> <span class="proc">Worker B</span> + <span class="proc">B.ChildSup</span>
              <span class="dim">&#9492;&#9472;&#9472;</span> <span class="proc">Worker C</span>

<span class="dim">If A crashes, A.ChildSup terminates B (and transitively C).</span></div>

        <div class="comparison">
          <div style="border-left: 3px solid var(--green);">
            <h4 style="color: var(--green);">Advantages</h4>
            <ul style="padding-left: 18px;">
              <li><strong>Automatic subtree cleanup:</strong> OTP handles cascading
                  termination. No orphaned processes.</li>
              <li><strong>Mirrors the logical tree:</strong> The supervision tree matches
                  the recursion tree. This is the OTP-native way to model parent-child
                  relationships.</li>
              <li><strong>Eliminates <code>pending_monitors</code>:</strong> No need to
                  manually monitor children&mdash;the supervisor handles lifecycle.</li>
            </ul>
          </div>
          <div style="border-left: 3px solid var(--red);">
            <h4 style="color: var(--red);">Disadvantages</h4>
            <ul style="padding-left: 18px;">
              <li><strong>More complex startup:</strong> Each Worker must start its own
                  DynamicSupervisor as a child. This requires either a child spec that
                  includes a supervisor, or starting the supervisor dynamically in
                  <code>init/1</code> (which adds latency).</li>
              <li><strong>Registry naming conflicts:</strong> Multiple DynamicSupervisors
                  need unique names. The Registry would need a new namespace for
                  per-Worker supervisors.</li>
              <li><strong>Restart semantics are complex:</strong> With <code>:temporary</code>
                  workers, a parent crash terminates the supervisor, which terminates
                  children. But what if you want children to be able to complete even if
                  the parent has a non-fatal error? The coupling becomes too tight.</li>
              <li><strong>Diminishing returns:</strong> In practice, parent Workers rarely
                  crash. The orphan problem exists in theory but is uncommon. The
                  engineering cost may not justify the reliability gain.</li>
            </ul>
          </div>
        </div>
      </div>
    </details>

    <!-- ---- Alt 5: Message Broker ---- -->
    <details>
      <summary>Alternative 5: Central Message Broker</summary>
      <div class="content">
        <p><span class="tag tag-maintenance">MAINT</span> <span class="tag tag-legibility">READ</span></p>

        <h4>Core Idea</h4>
        <p>
          Introduce a central <strong>Broker</strong> GenServer (per run) that mediates all
          inter-Worker communication. Workers don't know about each other's PIDs.
          They send subcall requests to the Broker, which spawns children, routes results,
          and manages the subcall lifecycle.
        </p>

        <div class="diagram"><span class="label">Broker-Mediated Communication</span>

<span class="proc">Eval</span> <span class="dim">&rarr;</span> <span class="fn">lm_query("task")</span> <span class="dim">&rarr;</span> <span class="proc">Broker</span> <span class="dim">&rarr;</span> <span class="action">spawn</span> <span class="dim">&rarr;</span> <span class="proc">Child Worker</span>
                                 <span class="dim">&#9474;</span>
                                 <span class="dim">&#9474;</span> <span class="dim">Routes result back:</span>
                                 <span class="dim">&#9474;</span>
<span class="proc">Child Worker</span> <span class="dim">&rarr;</span> <span class="msg">{:done, result}</span> <span class="dim">&rarr;</span> <span class="proc">Broker</span> <span class="dim">&rarr;</span> <span class="action">reply to Eval</span>
                                 <span class="dim">&#9474;</span>
                                 <span class="dim">&#9492;&#9472;</span> <span class="dim">Also handles: depth checks,</span>
                                    <span class="dim">concurrency limits, monitoring,</span>
                                    <span class="dim">crash cleanup, telemetry</span></div>

        <div class="comparison">
          <div style="border-left: 3px solid var(--green);">
            <h4 style="color: var(--green);">Advantages</h4>
            <ul style="padding-left: 18px;">
              <li><strong>Workers become simpler:</strong> A Worker just runs its iterate
                  loop. Subcall management, monitoring, and routing are the Broker's
                  responsibility. The Worker module shrinks significantly.</li>
              <li><strong>Centralized observability:</strong> The Broker has a global view
                  of all in-flight subcalls, depths, and concurrency. Debugging and
                  inspection become trivial.</li>
              <li><strong>Single point for policy:</strong> Rate limiting, depth checks,
                  priority queuing, and circuit breaking all live in one place.</li>
              <li><strong>No <code>pending_subcalls</code> in Workers:</strong>
                  The Broker owns the mapping. Workers are stateless with respect to
                  subcalls.</li>
            </ul>
          </div>
          <div style="border-left: 3px solid var(--red);">
            <h4 style="color: var(--red);">Disadvantages</h4>
            <ul style="padding-left: 18px;">
              <li><strong>Single point of failure:</strong> If the Broker crashes, all
                  in-flight subcalls are lost. It becomes a critical path component.</li>
              <li><strong>Bottleneck:</strong> All subcall messages flow through one process.
                  Under high concurrency (many parallel_query calls), the Broker's mailbox
                  could become a bottleneck.</li>
              <li><strong>Added latency:</strong> Every message has an extra hop through the
                  Broker. For simple subcalls, this adds overhead.</li>
              <li><strong>The async-eval pattern is still needed:</strong> If eval calls
                  <code>lm_query()</code> and that calls the Broker (not the Worker), the
                  deadlock shifts but doesn't vanish unless the Broker is a separate
                  process from the Worker&mdash;which it is, but the eval process still
                  blocks on the GenServer.call to the Broker while the Worker is idle.</li>
            </ul>
          </div>
        </div>
      </div>
    </details>
  </div>
</section>

<!-- ================================================================== -->
<!-- SECTION 11: VERDICT -->
<!-- ================================================================== -->
<section id="verdict">
  <div class="container">
    <h2><span class="section-num">11</span> Comparative Verdict</h2>

    <table>
      <thead>
        <tr>
          <th>Architecture</th>
          <th>OTP Native</th>
          <th>Legibility</th>
          <th>Error Handling</th>
          <th>Maintenance</th>
          <th>Concurrency</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Current (GenServer + async eval)</strong></td>
          <td style="color: var(--yellow);">Partial</td>
          <td style="color: var(--yellow);">Moderate</td>
          <td style="color: var(--green);">Good</td>
          <td style="color: var(--yellow);">Moderate</td>
          <td style="color: var(--green);">Excellent</td>
        </tr>
        <tr>
          <td><strong>Alt 1: gen_statem</strong></td>
          <td style="color: var(--green);">Excellent</td>
          <td style="color: var(--yellow);">Mixed</td>
          <td style="color: var(--green);">Good</td>
          <td style="color: var(--yellow);">Moderate</td>
          <td style="color: var(--green);">Same</td>
        </tr>
        <tr>
          <td><strong>Alt 2: Coordinator + Runner</strong></td>
          <td style="color: var(--green);">Good</td>
          <td style="color: var(--green);">High</td>
          <td style="color: var(--green);">Good</td>
          <td style="color: var(--yellow);">More code</td>
          <td style="color: var(--green);">Same</td>
        </tr>
        <tr>
          <td><strong>Alt 3: Continuations</strong></td>
          <td style="color: var(--green);">Excellent</td>
          <td style="color: var(--green);">Very High</td>
          <td style="color: var(--green);">Simple</td>
          <td style="color: var(--green);">Low</td>
          <td style="color: var(--red);">None</td>
        </tr>
        <tr>
          <td><strong>Alt 4: Supervisor-Per-Subtree</strong></td>
          <td style="color: var(--green);">Excellent</td>
          <td style="color: var(--yellow);">Same</td>
          <td style="color: var(--green);">Excellent</td>
          <td style="color: var(--red);">High</td>
          <td style="color: var(--green);">Same</td>
        </tr>
        <tr>
          <td><strong>Alt 5: Central Broker</strong></td>
          <td style="color: var(--green);">Good</td>
          <td style="color: var(--green);">High</td>
          <td style="color: var(--yellow);">SPOF risk</td>
          <td style="color: var(--yellow);">Moderate</td>
          <td style="color: var(--yellow);">Bottleneck</td>
        </tr>
      </tbody>
    </table>

    <h3>Bottom Line</h3>

    <div class="card note">
      <h4>The Current Architecture Is a Reasonable Trade-off</h4>
      <p>
        The async-eval pattern is driven by a <em>real</em> constraint: GenServer
        single-threaded message processing + code that calls back into the
        GenServer. Every alternative that preserves concurrent subcalls must solve
        the same fundamental problem. The current design solves it with the minimum
        number of additional processes (one extra spawn per iteration).
      </p>
      <p>
        The main costs&mdash;invisible control flow, large Worker module, implicit
        state machine&mdash;are manageable with documentation (like this document)
        and could be mitigated incrementally:
      </p>
      <ul style="padding-left: 18px; margin-top: 12px;">
        <li><strong>Short-term:</strong> Unify <code>pending_subcalls</code> and
            <code>pending_monitors</code> into a single <code>%PendingChild{}</code>
            struct map. Monitor direct-query processes. These are backward-compatible
            refactors.</li>
        <li><strong>Medium-term:</strong> Extract subcall management into a helper
            module (<code>RLM.Worker.Subcalls</code>) to shrink the Worker module.
            Move eval dispatch into <code>RLM.Worker.Eval</code>. Keep the GenServer
            but modularize its internals.</li>
        <li><strong>Long-term consideration:</strong> If the Worker continues growing
            in complexity, the Coordinator + Runner split (Alt 2) gives the cleanest
            separation without sacrificing concurrency. It's the natural evolution of
            the current design.</li>
      </ul>
    </div>

    <div class="verdict-grid">
      <div class="verdict-item">
        <div class="score mid" style="color: var(--accent);">B+</div>
        <div class="label">Overall Grade</div>
      </div>
      <div class="verdict-item">
        <div class="score high">A</div>
        <div class="label">Correctness</div>
      </div>
      <div class="verdict-item">
        <div class="score mid">B</div>
        <div class="label">OTP Conformity</div>
      </div>
      <div class="verdict-item">
        <div class="score mid">B-</div>
        <div class="label">Legibility</div>
      </div>
    </div>
  </div>
</section>

<footer style="padding: 40px 0; text-align: center; color: var(--text-dim); font-size: 0.82rem; border-top: 1px solid var(--border);">
  <div class="container">
    RLM Architecture Discussion &mdash; Generated Feb 2026<br>
    <span style="color: var(--accent);">docs/architecture-discussion.html</span>
  </div>
</footer>

</body>
</html>
