<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>RLM Engine &mdash; System Review &amp; OTP Assessment</title>
<style>
  :root {
    --bg: #0d1117; --fg: #c9d1d9; --accent: #58a6ff; --accent2: #7ee787;
    --warn: #d29922; --err: #f85149; --card: #161b22; --border: #30363d;
    --code-bg: #1c2128; --heading: #f0f6fc;
    --purple: #bc8cff; --teal: #39d353;
  }
  * { box-sizing: border-box; margin: 0; padding: 0; }
  body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
    background: var(--bg); color: var(--fg); line-height: 1.7;
    padding: 2rem; max-width: 1100px; margin: 0 auto;
  }
  h1 { color: var(--heading); font-size: 2rem; margin-bottom: .5rem; border-bottom: 2px solid var(--accent); padding-bottom: .5rem; }
  h2 { color: var(--accent); font-size: 1.5rem; margin: 2.5rem 0 1rem; }
  h3 { color: var(--accent2); font-size: 1.15rem; margin: 1.5rem 0 .5rem; }
  h4 { color: var(--purple); font-size: 1rem; margin: 1rem 0 .4rem; }
  p, li { margin-bottom: .6rem; }
  ul, ol { padding-left: 1.5rem; }
  a { color: var(--accent); text-decoration: none; }
  a:hover { text-decoration: underline; }
  code { background: var(--code-bg); padding: 2px 6px; border-radius: 4px; font-size: .9em; color: var(--accent2); }
  pre { background: var(--code-bg); padding: 1rem; border-radius: 8px; overflow-x: auto; margin: 1rem 0;
        border: 1px solid var(--border); font-size: .85em; line-height: 1.5; }
  pre code { background: none; padding: 0; color: var(--fg); }
  .card { background: var(--card); border: 1px solid var(--border); border-radius: 8px; padding: 1.5rem; margin: 1rem 0; }
  .grid { display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; }
  .grid-3 { display: grid; grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); gap: 1rem; }
  @media (max-width: 700px) { .grid, .grid-3 { grid-template-columns: 1fr; } }
  .badge { display: inline-block; padding: 2px 10px; border-radius: 12px; font-size: .8em; font-weight: 600; }
  .good { background: #1a3a2a; color: var(--accent2); }
  .warn { background: #3a2a1a; color: var(--warn); }
  .err  { background: #3a1a1a; color: var(--err); }
  .info { background: #1a2a3a; color: var(--accent); }
  table { width: 100%; border-collapse: collapse; margin: 1rem 0; }
  th, td { text-align: left; padding: .5rem .75rem; border-bottom: 1px solid var(--border); }
  th { color: var(--accent); font-size: .85em; text-transform: uppercase; letter-spacing: .05em; }
  .toc { background: var(--card); border: 1px solid var(--border); border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; }
  .toc ol { counter-reset: toc; list-style: none; padding-left: 0; }
  .toc li { counter-increment: toc; margin-bottom: .3rem; }
  .toc li::before { content: counter(toc) ". "; color: var(--accent); font-weight: 600; }
  .diagram { background: var(--code-bg); border: 1px solid var(--border); border-radius: 8px; padding: 1.5rem; margin: 1rem 0;
             font-family: monospace; white-space: pre; line-height: 1.4; font-size: .85em; overflow-x: auto; }
  .subtitle { color: #8b949e; font-size: 1rem; margin-bottom: 2rem; }
  hr { border: none; border-top: 1px solid var(--border); margin: 3rem 0; }
  .score { font-size: 2.5rem; font-weight: 800; color: var(--accent2); }
  .score-label { font-size: .85rem; color: #8b949e; text-transform: uppercase; letter-spacing: 0.05em; }
  .tier { border-left: 4px solid; padding-left: 16px; margin-bottom: 16px; }
  .tier-good { border-color: var(--accent2); }
  .tier-ok { border-color: var(--warn); }
  .tier-improve { border-color: var(--err); }
  .priority { display: inline-block; width: 6px; height: 6px; border-radius: 50%; margin-right: 6px; }
  .p-high { background: var(--err); }
  .p-med { background: var(--warn); }
  .p-low { background: var(--accent); }
</style>
</head>
<body>

<h1>RLM Engine &mdash; System Review &amp; OTP Assessment</h1>
<p class="subtitle">Comprehensive analysis of the current codebase, OTP design quality, and recommendations &mdash; February 2026</p>

<nav class="toc">
<strong>Contents</strong>
<ol>
  <li><a href="#s1">Executive Summary</a></li>
  <li><a href="#s2">What Works Well</a></li>
  <li><a href="#s3">OTP Assessment</a></li>
  <li><a href="#s4">Naming &amp; Organization</a></li>
  <li><a href="#s5">Gaps &amp; Missing Features</a></li>
  <li><a href="#s6">Python RLM Comparison</a></li>
  <li><a href="#s7">Architectural Recommendations</a></li>
  <li><a href="#s8">Testing Assessment</a></li>
  <li><a href="#s9">Future Directions</a></li>
</ol>
</nav>

<!-- ================================================================ -->
<h2 id="s1">1. Executive Summary</h2>

<div class="card">
<p>The RLM Elixir engine has evolved from a basic recursive language model to a <strong>unified, production-capable system</strong>. Two major milestones shipped in Feb 2026:</p>
<ul>
  <li><strong>LiveView Dashboard</strong> &mdash; Real-time trace visualization with :dets persistence</li>
  <li><strong>Agent-to-Engine Consolidation</strong> (PR #6) &mdash; Merged the separate <code>RLM.Agent.*</code> namespace into the core engine, eliminating 15 files of duplication</li>
</ul>

<p>The result is a clean, single-engine architecture with <strong>111 passing tests</strong> (98 rlm + 13 rlm_web), 8 OTP supervision tree children, 7 filesystem tools, 15 telemetry events, and a Phoenix LiveView dashboard.</p>
</div>

<div class="grid">
  <div class="card" style="text-align:center;">
    <div class="score">8/10</div>
    <div class="score-label">OTP Design Score</div>
    <p style="margin-top:.5rem; font-size:.9rem;">Genuinely idiomatic in core patterns; a few areas for improvement</p>
  </div>
  <div class="card">
    <h4>Current State</h4>
    <table style="margin:0;">
      <tr><td>Test suite</td><td><span class="badge good">111 passing</span></td></tr>
      <tr><td>Modules</td><td>~34 modules across 2 apps</td></tr>
      <tr><td>Supervision children</td><td>8 processes</td></tr>
      <tr><td>Telemetry events</td><td>15 defined, 12 actively emitted</td></tr>
      <tr><td>Tools</td><td>7 filesystem tools</td></tr>
      <tr><td>Config fields</td><td>21 on <code>RLM.Config</code></td></tr>
    </table>
  </div>
</div>

<!-- ================================================================ -->
<h2 id="s2">2. What Works Well</h2>

<div class="grid-3">
  <div class="card">
    <h4><span class="badge good">Excellent</span> Async-Eval Pattern</h4>
    <p>The Worker spawns eval in a separate process, keeping its mailbox free for <code>{:spawn_subcall, ...}</code> calls. This prevents deadlock when eval'd code calls <code>lm_query()</code>. The pattern is subtle and correctly implemented.</p>
    <p><code>worker.ex:467</code> &mdash; <code>spawn(fn -> Eval.run(...) end)</code></p>
  </div>

  <div class="card">
    <h4><span class="badge good">Excellent</span> Unified Worker</h4>
    <p>A single <code>RLM.Worker</code> GenServer handles both one-shot and interactive modes. State machine transitions (<code>:idle</code> &harr; <code>:running</code>) are clean. No code duplication between modes.</p>
  </div>

  <div class="card">
    <h4><span class="badge good">Excellent</span> Supervision Tree</h4>
    <p>8 children with appropriate restart strategies. Workers are <code>:temporary</code> (correct for one-shot tasks). Infrastructure is <code>:permanent</code>. <code>one_for_one</code> strategy prevents cascading failures.</p>
  </div>

  <div class="card">
    <h4><span class="badge good">Excellent</span> Registry Usage</h4>
    <p><code>{:via, Registry, {RLM.Registry, {:worker, span_id}}}</code> provides clean process lookup without global state or atoms. Used consistently for both Workers and EventLog agents.</p>
  </div>

  <div class="card">
    <h4><span class="badge good">Excellent</span> Tool System Design</h4>
    <p>Simple, effective <code>@behaviour</code> with three callbacks. Tools are stateless functions &mdash; no unnecessary OTP overhead. Sandbox wrappers provide ergonomic eval-accessible API with CWD-relative path resolution.</p>
  </div>

  <div class="card">
    <h4><span class="badge good">Excellent</span> Telemetry Pipeline</h4>
    <p>15 well-defined events with clean separation of concerns across 3 handlers. Follows the standard <code>:telemetry</code> convention. PubSub broadcasting enables real-time LiveView updates.</p>
  </div>

  <div class="card">
    <h4><span class="badge good">Good</span> Dual-Write Tracing</h4>
    <p><code>EventLogHandler</code> writes to both in-memory Agent (fast queries) and :dets (persistence). The fallback pattern in <code>RunDetailLive.load_spans/1</code> seamlessly handles swept agents.</p>
  </div>

  <div class="card">
    <h4><span class="badge good">Good</span> Sweeper GC</h4>
    <p>Separate monotonic vs. wall-clock cutoffs correctly handle the two different time bases. <code>safe_get_started_at/1</code> with rescue/catch prevents the sweeper from crashing on unresponsive agents.</p>
  </div>

  <div class="card">
    <h4><span class="badge good">Good</span> MockLLM Testing</h4>
    <p>ETS-based mock with response queue enables deterministic multi-turn test scenarios. Clean dependency injection via <code>llm_module</code> config field.</p>
  </div>
</div>

<!-- ================================================================ -->
<h2 id="s3">3. OTP Assessment <span class="badge info">8/10</span></h2>

<div class="tier tier-good">
<h3>Tier 1: Genuinely Idiomatic <span class="badge good">Well Done</span></h3>

<h4>Async-Eval Deadlock Prevention</h4>
<p>The core architectural decision &mdash; spawning eval in a separate process so the Worker can handle subcall requests &mdash; is textbook OTP thinking. The pattern correctly identifies that <code>GenServer.call</code> from within a synchronous callback would deadlock.</p>
<pre><code># worker.ex:464-477
spawn(fn ->
  result = RLM.Eval.run(code, state.bindings,
    timeout: state.config.eval_timeout,
    worker_pid: worker_pid,
    bindings_info: RLM.Helpers.list_bindings(state.bindings),
    cwd: state.cwd
  )
  send(worker_pid, {:eval_complete, result})
end)</code></pre>

<h4>Registry for Named Processes</h4>
<p>Using <code>{:via, Registry, ...}</code> with compound keys like <code>{:worker, span_id}</code> and <code>{:event_log, run_id}</code> is the correct modern approach. No global atoms, no name collisions, automatic cleanup on process exit.</p>

<h4>DynamicSupervisor for Workers</h4>
<p>Workers are supervised but <code>:temporary</code> &mdash; they terminate normally after task completion and are never restarted. This is exactly right for task-oriented processes.</p>

<h4>Process.monitor in RLM.run/3</h4>
<p>The caller monitors the Worker so crashes surface as <code>{:error, reason}</code> rather than hanging indefinitely. The timeout fallback with explicit <code>DynamicSupervisor.terminate_child/2</code> prevents resource leaks.</p>
</div>

<div class="tier tier-ok">
<h3>Tier 2: Passable &mdash; Works Correctly, Minor Improvements Possible <span class="badge warn">Fine</span></h3>

<h4>RLM.Telemetry GenServer</h4>
<p>A GenServer whose only job is calling <code>:telemetry.attach_many/4</code> in <code>init/1</code> is heavier than needed. A simpler approach would be a module function called from <code>Application.start/2</code>. However, the GenServer does provide a clean <code>detach_all_handlers/0</code> for testing, so there's a practical reason to keep it.</p>

<h4>EventLog as Agent</h4>
<p>Using <code>Agent</code> for EventLog is straightforward but means the tree-building logic (<code>update_tree/2</code>) runs inside the Agent's process. For the current scale this is fine. If events become high-frequency, the serialization point could become a bottleneck.</p>

<h4>TraceStore :dets Access Patterns</h4>
<p><code>list_run_ids/0</code> does a full table fold on every call. With hundreds of runs this is fine; with thousands it could slow down. An ETS index or caching layer would help at scale.</p>

<h4>Bare spawn for Eval</h4>
<p>The eval process is started with <code>spawn/1</code> rather than being supervised. If the eval process crashes silently, the Worker only knows via <code>{:DOWN, ...}</code> from Process.monitor &mdash; but there's actually no monitor set up. The Worker relies on the eval process always sending <code>{:eval_complete, ...}</code>. In practice, the try/rescue/catch in <code>RLM.Eval.run/3</code> makes this safe, but a <code>spawn_monitor/1</code> would be more defensive.</p>
</div>

<div class="tier tier-improve">
<h3>Tier 3: Non-Idiomatic &mdash; Worth Addressing <span class="badge err">Improve</span></h3>

<h4>No Monitor on Eval Process</h4>
<p>If <code>spawn(fn -> Eval.run(...); send(worker, {:eval_complete, result}) end)</code> crashes between computing the result and sending the message, the Worker hangs in the <code>:eval_context</code> state indefinitely. Adding <code>spawn_monitor</code> and a <code>{:DOWN, ...}</code> handler would make this bulletproof.</p>

<h4>History as List Append</h4>
<p>Message history uses <code>state.history ++ [new_msg]</code> which is O(n) list append. For typical sessions (tens of messages) this is negligible. For very long sessions it would accumulate. A queue or reverse-list-then-reverse pattern would be more idiomatic.</p>

<h4>Missing Application.stop Cleanup</h4>
<p>The :dets table is closed in <code>TraceStore.terminate/2</code>, but if the application stops ungracefully, :dets auto-repair handles it. No issues observed, but explicit <code>Application.stop/0</code> callback would be cleaner.</p>
</div>
</section>

<!-- ================================================================ -->
<h2 id="s4">4. Naming &amp; Organization</h2>

<h3>Rename Proposals</h3>
<table>
  <tr><th>Current Name</th><th>Proposed Name</th><th>Rationale</th><th>Priority</th></tr>
  <tr>
    <td><code>RLM.EventStore</code> (DynamicSupervisor)</td>
    <td><code>RLM.EventLogSupervisor</code></td>
    <td>"EventStore" suggests a database/persistence layer (event sourcing). It's actually a DynamicSupervisor for EventLog Agents. The name is misleading.</td>
    <td><span class="badge warn">Medium</span></td>
  </tr>
  <tr>
    <td><code>RLM.Telemetry</code> (GenServer)</td>
    <td>(consider removing)</td>
    <td>Could be replaced by a function call in <code>Application.start/2</code>. But the GenServer provides clean attach/detach for tests, so keeping it is defensible.</td>
    <td><span class="badge info">Low</span></td>
  </tr>
  <tr>
    <td><code>telemetry/telemetry.ex</code></td>
    <td><code>telemetry.ex</code> (move up)</td>
    <td>The file is nested inside the <code>telemetry/</code> directory as <code>telemetry/telemetry.ex</code>. Moving it to <code>lib/rlm/telemetry.ex</code> would be cleaner, or rename to <code>telemetry/setup.ex</code>.</td>
    <td><span class="badge info">Low</span></td>
  </tr>
</table>

<h3>What to Keep Unchanged (and Why)</h3>
<table>
  <tr><th>Name</th><th>Rationale for Keeping</th></tr>
  <tr><td><code>RLM.Worker</code></td><td>Clear and accurate &mdash; it's a worker process that does work. "Engine" or "Node" would be less precise.</td></tr>
  <tr><td><code>RLM.Sandbox</code></td><td>Correctly communicates the security boundary even though it's not a true sandbox. The name sets the right expectation.</td></tr>
  <tr><td><code>RLM.Eval</code></td><td>Short, accurate, matches the Elixir ecosystem convention (Code.eval_string).</td></tr>
  <tr><td><code>RLM.Tool</code> / <code>RLM.ToolRegistry</code></td><td>Standard naming for behaviour + registry pattern. Well-understood.</td></tr>
  <tr><td><code>RLM.EventLog</code></td><td>Clear name for what it does &mdash; logs events per run.</td></tr>
  <tr><td><code>RLM.TraceStore</code></td><td>Accurate &mdash; stores traces persistently.</td></tr>
</table>

<!-- ================================================================ -->
<h2 id="s5">5. Gaps &amp; Missing Features</h2>

<table>
  <tr><th>Gap</th><th>Impact</th><th>Effort</th><th>Priority</th></tr>
  <tr>
    <td><strong>Cost Tracking</strong><br>Token usage is in telemetry events but not aggregated per run or exposed via API</td>
    <td><span class="badge warn">Medium</span></td>
    <td><span class="badge good">Low</span></td>
    <td><span class="priority p-high"></span> High</td>
  </tr>
  <tr>
    <td><strong>SSE Streaming</strong><br>Removed during Agent consolidation. Users can't see partial LLM responses in real-time</td>
    <td><span class="badge warn">Medium</span></td>
    <td><span class="badge warn">Medium</span></td>
    <td><span class="priority p-high"></span> High</td>
  </tr>
  <tr>
    <td><strong>Smarter Compaction</strong><br>Current approach serializes all history as a string. No LLM-based summarization</td>
    <td><span class="badge info">Low</span></td>
    <td><span class="badge warn">Medium</span></td>
    <td><span class="priority p-med"></span> Medium</td>
  </tr>
  <tr>
    <td><strong>Permission Model</strong><br>No restrictions on which tools/directories are accessible. No approval flow for dangerous operations</td>
    <td><span class="badge warn">Medium</span></td>
    <td><span class="badge warn">Medium</span></td>
    <td><span class="priority p-med"></span> Medium</td>
  </tr>
  <tr>
    <td><strong>Session Persistence</strong><br>Keep-alive sessions are lost on restart. No way to resume a session across server restarts</td>
    <td><span class="badge info">Low</span></td>
    <td><span class="badge err">High</span></td>
    <td><span class="priority p-low"></span> Low</td>
  </tr>
  <tr>
    <td><strong>Eval Process Monitor</strong><br>Worker doesn't monitor the spawned eval process. Silent crashes cause hangs.</td>
    <td><span class="badge warn">Medium</span></td>
    <td><span class="badge good">Low</span></td>
    <td><span class="priority p-high"></span> High</td>
  </tr>
  <tr>
    <td><strong>Dashboard Authentication</strong><br>Dashboard is open with no auth. Fine for dev, not for production.</td>
    <td><span class="badge info">Low</span></td>
    <td><span class="badge good">Low</span></td>
    <td><span class="priority p-low"></span> Low</td>
  </tr>
</table>

<!-- ================================================================ -->
<h2 id="s6">6. Python RLM Comparison</h2>

<table>
  <tr><th>Capability</th><th>Python RLM</th><th>Elixir RLM</th><th>Notes</th></tr>
  <tr>
    <td>Core iterate loop</td>
    <td><span class="badge good">Yes</span></td>
    <td><span class="badge good">Yes</span></td>
    <td>Functionally equivalent. Elixir uses GenServer state machine vs. Python's async loop.</td>
  </tr>
  <tr>
    <td>Recursive subcalls</td>
    <td><span class="badge good">Yes</span></td>
    <td><span class="badge good">Yes</span></td>
    <td>Elixir uses DynamicSupervisor for child Workers. Better fault isolation.</td>
  </tr>
  <tr>
    <td>Parallel subcalls</td>
    <td><span class="badge good">Yes</span></td>
    <td><span class="badge good">Yes</span></td>
    <td><code>parallel_query/2</code> with <code>Task.await_many</code>. Depth + concurrency limits.</td>
  </tr>
  <tr>
    <td>Three invariants</td>
    <td><span class="badge good">Yes</span></td>
    <td><span class="badge good">Yes</span></td>
    <td>Preview-only context, variable-stored subcall results, head+tail truncation.</td>
  </tr>
  <tr>
    <td>Context compaction</td>
    <td><span class="badge good">LLM-based</span></td>
    <td><span class="badge warn">String serialization</span></td>
    <td>Python uses LLM to summarize. Elixir serializes to string and stores in binding. Less intelligent but simpler.</td>
  </tr>
  <tr>
    <td>Interactive sessions</td>
    <td><span class="badge err">No</span></td>
    <td><span class="badge good">Yes</span></td>
    <td>Elixir's keep-alive mode is unique. Bindings persist across turns.</td>
  </tr>
  <tr>
    <td>Filesystem tools</td>
    <td><span class="badge err">No</span></td>
    <td><span class="badge good">7 tools</span></td>
    <td>ReadFile, WriteFile, EditFile, Bash, Grep, Glob, Ls. Python only has eval.</td>
  </tr>
  <tr>
    <td>Tool integration</td>
    <td><span class="badge warn">Eval only</span></td>
    <td><span class="badge good">Sandbox functions</span></td>
    <td>Tools are Elixir functions called from eval'd code. More natural than API tool_use.</td>
  </tr>
  <tr>
    <td>Structured tracing</td>
    <td><span class="badge warn">Basic logging</span></td>
    <td><span class="badge good">15 events + :dets</span></td>
    <td>Full telemetry pipeline with 3 handlers, in-memory + persistent dual-write.</td>
  </tr>
  <tr>
    <td>Visualization</td>
    <td><span class="badge err">None</span></td>
    <td><span class="badge good">LiveView dashboard</span></td>
    <td>Real-time span tree with expandable iterations, status badges, token counts.</td>
  </tr>
  <tr>
    <td>Fault tolerance</td>
    <td><span class="badge warn">Try/except</span></td>
    <td><span class="badge good">OTP supervision</span></td>
    <td>Supervised processes, :temporary restart, Process.monitor on callers.</td>
  </tr>
  <tr>
    <td>Streaming</td>
    <td><span class="badge good">SSE</span></td>
    <td><span class="badge err">Removed</span></td>
    <td>Was in RLM.Agent.LLM, removed during consolidation. Needs re-implementation.</td>
  </tr>
  <tr>
    <td>Cost tracking</td>
    <td><span class="badge good">Per-run</span></td>
    <td><span class="badge warn">Events only</span></td>
    <td>Token counts in telemetry; cost config fields defined but not aggregated.</td>
  </tr>
</table>

<!-- ================================================================ -->
<h2 id="s7">7. Architectural Recommendations</h2>

<h3>Do</h3>

<div class="card">
<h4>1. Add spawn_monitor to eval process <span class="badge good">Quick Win</span></h4>
<p>Replace <code>spawn(fn -> ... end)</code> with <code>spawn_monitor(fn -> ... end)</code> in <code>Worker.start_async_eval/6</code>. Handle <code>{:DOWN, ref, :process, pid, reason}</code> to catch silent eval crashes. This is a 5-line change that prevents a real failure mode.</p>
</div>

<div class="card">
<h4>2. Aggregate cost per run <span class="badge good">Quick Win</span></h4>
<p>Add an accumulator to EventLog (or a new field on the tree nodes) that sums <code>llm_prompt_tokens</code> and <code>llm_completion_tokens</code> per run. Multiply by the config cost rates. Expose via <code>EventLog.get_cost/1</code> and show on the dashboard.</p>
</div>

<div class="card">
<h4>3. Re-add streaming to RLM.LLM <span class="badge warn">Medium Effort</span></h4>
<p>The streaming implementation was in <code>RLM.Agent.LLM</code> and was removed during consolidation. Add an <code>RLM.LLM.chat_stream/4</code> function that yields <code>:telemetry</code> events for partial responses. The Worker doesn't need to change &mdash; streaming is orthogonal to the iterate loop.</p>
</div>

<div class="card">
<h4>4. Rename EventStore to EventLogSupervisor <span class="badge info">Low Priority</span></h4>
<p>"EventStore" is a loaded term in event-sourcing contexts. <code>RLM.EventLogSupervisor</code> or <code>RLM.EventLogSup</code> is clearer. This is a rename in <code>application.ex</code> + <code>event_log_handler.ex</code> + <code>event_log_sweeper.ex</code>.</p>
</div>

<h3>Don't</h3>

<div class="card">
<h4>Don't switch to Anthropic tool_use protocol</h4>
<p>The current approach (LLM writes Elixir code that calls sandbox functions) is more natural and more powerful than structured <code>tool_use</code>. The LLM can compose tool calls, use conditionals, and process results in a single code block. Switching to tool_use would lose this expressiveness.</p>
</div>

<div class="card">
<h4>Don't add ETS caching for TraceStore reads</h4>
<p>The :dets read performance is adequate for the current scale (hundreds of runs). Adding an ETS cache would introduce cache invalidation complexity. Wait until profiling shows it's actually a bottleneck.</p>
</div>

<div class="card">
<h4>Don't make Workers :permanent or :transient</h4>
<p><code>:temporary</code> is correct. Workers represent individual tasks that should not be automatically restarted. A crashed Worker should surface its error to the caller, not silently retry.</p>
</div>

<div class="card">
<h4>Don't add a process pool for Workers</h4>
<p>Workers are short-lived and individually supervised. A pool adds complexity without benefit &mdash; there's no warm-up cost and no shared state to amortize. DynamicSupervisor is the right tool.</p>
</div>

<!-- ================================================================ -->
<h2 id="s8">8. Testing Assessment</h2>

<div class="grid">
  <div class="card">
    <h4>Current Coverage</h4>
    <table style="margin:0;">
      <tr><td>Total tests</td><td><strong>111</strong> (98 rlm + 13 rlm_web)</td></tr>
      <tr><td>Worker tests</td><td>Integration + keep-alive + PubSub</td></tr>
      <tr><td>Tool tests</td><td>All 7 tools with temp directory setup</td></tr>
      <tr><td>Sandbox tests</td><td>Eval + sandbox function integration</td></tr>
      <tr><td>LiveView tests</td><td>Basic mount + rendering</td></tr>
      <tr><td>Live API tests</td><td>Tagged <code>:live_api</code>, excluded by default</td></tr>
      <tr><td>MockLLM</td><td>ETS-based response queue, deterministic</td></tr>
    </table>
  </div>
  <div class="card">
    <h4>Testing Strengths</h4>
    <ul style="margin:0;">
      <li><span class="badge good">Good</span> MockLLM enables fast, deterministic tests</li>
      <li><span class="badge good">Good</span> Worker concurrency tests spawn real processes</li>
      <li><span class="badge good">Good</span> Tool tests use isolated temp directories</li>
      <li><span class="badge good">Good</span> <code>async: false</code> correctly used where needed</li>
      <li><span class="badge good">Good</span> Live API tests separated with tag</li>
    </ul>
  </div>
</div>

<h3>Testing Gaps</h3>
<table>
  <tr><th>Gap</th><th>Impact</th><th>Recommendation</th></tr>
  <tr>
    <td>No property-based tests</td>
    <td><span class="badge info">Low</span></td>
    <td>StreamData for <code>Truncate</code>, <code>Helpers.chunks</code>, and <code>Helpers.grep</code> edge cases</td>
  </tr>
  <tr>
    <td>No load/stress tests</td>
    <td><span class="badge warn">Medium</span></td>
    <td>Spawn 50+ concurrent Workers to validate supervision tree under load</td>
  </tr>
  <tr>
    <td>Shallow LiveView tests</td>
    <td><span class="badge warn">Medium</span></td>
    <td>Test PubSub-driven updates: new run appearing, status changing, iteration expansion</td>
  </tr>
  <tr>
    <td>No TraceStore persistence tests</td>
    <td><span class="badge warn">Medium</span></td>
    <td>Test that events survive GenServer restart. Test <code>delete_older_than</code> cleanup.</td>
  </tr>
  <tr>
    <td>No compaction test</td>
    <td><span class="badge warn">Medium</span></td>
    <td>Test <code>maybe_compact</code> triggers when history exceeds 80% of context window</td>
  </tr>
  <tr>
    <td>No Sweeper integration test</td>
    <td><span class="badge info">Low</span></td>
    <td>Test that Sweeper terminates old EventLog agents after TTL</td>
  </tr>
</table>

<!-- ================================================================ -->
<h2 id="s9">9. Future Directions</h2>

<p>Ordered by value/effort ratio, highest first:</p>

<div class="card">
<h4><span class="priority p-high"></span> 1. Cost Tracking &amp; Budget Limits <span class="badge good">High Value / Low Effort</span></h4>
<p>Aggregate token usage per run. Apply cost rates from config. Add <code>max_cost_per_run</code> config field. Show cost in dashboard. This is mostly additive &mdash; token counts already flow through telemetry.</p>
</div>

<div class="card">
<h4><span class="priority p-high"></span> 2. Eval Process Safety <span class="badge good">High Value / Low Effort</span></h4>
<p>Switch from <code>spawn</code> to <code>spawn_monitor</code> for the eval process. Handle <code>{:DOWN, ...}</code> to prevent Worker hangs. A targeted, low-risk fix.</p>
</div>

<div class="card">
<h4><span class="priority p-high"></span> 3. SSE Streaming <span class="badge warn">High Value / Medium Effort</span></h4>
<p>Re-add streaming to <code>RLM.LLM</code>. Broadcast partial tokens via PubSub for LiveView consumption. Users see the LLM "thinking" in real-time. Previously implemented but needs adaptation to the unified architecture.</p>
</div>

<div class="card">
<h4><span class="priority p-med"></span> 4. Session Persistence <span class="badge warn">Medium Value / Medium Effort</span></h4>
<p>Serialize keep-alive Worker state (history + bindings) to :dets or Mnesia. Resume sessions after restart. Requires careful handling of non-serializable bindings (PIDs, ports, refs).</p>
</div>

<div class="card">
<h4><span class="priority p-med"></span> 5. LLM-Based Compaction <span class="badge warn">Medium Value / Medium Effort</span></h4>
<p>Replace string serialization with an LLM summarization call. Send the history to a small model with a "summarize this conversation" prompt. Better context retention at the cost of an extra API call.</p>
</div>

<div class="card">
<h4><span class="priority p-low"></span> 6. Permission Model <span class="badge err">Medium Value / High Effort</span></h4>
<p>Add a permission layer for tool execution. Allow/deny patterns for file paths, command restrictions for bash. Approval callbacks for dangerous operations. Significant design work needed.</p>
</div>

<hr>

<p style="color:#8b949e; font-size:.85rem; text-align:center;">
  RLM Engine System Review &mdash; Generated February 2026 &mdash; Based on codebase analysis of apps/rlm and apps/rlm_web
</p>

</body>
</html>
